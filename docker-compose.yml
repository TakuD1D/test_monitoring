services:
  tkmk-prometheus:
    image: prom/prometheus:latest
    user: root
    container_name: tkmk-prometheus
    ports:
      - 18323:9090 # 自分たちが割り振られている範囲のhostport:containerport
    volumes:
      - ./prom_config:/etc/prometheus/
      - metrics_data:/prometheus
    command: 
      - "--config.file=/etc/prometheus/prometheus.yml" # これ追加しないとloaderrorが出る
      - "--storage.tsdb.retention.time=3d" # データ保持期間 resource管理のみなので
    restart: always
    networks:
      - monitoring_default
  grafana:
    # image: grafana/grafana
    build:
      context: .
      dockerfile: Dockerfile
    container_name: grafana
    ports:
      - 18324:3000   # 自分たちが割り振られている範囲のhostport:containerport

    volumes:
      # - ./grafana/dashboard:/var/lib/grafana/dashboards
      # - ./grafana/config/***.ini:/etc/grafana/grafana.ini
      - ./grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/dashboard.yml
      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml
    restart: always
    # entrypoint: "bash /var/lib/grafana/dashboards/json_sub.sh"
    # environment:
      # - DS_PROMETHEUS=prometheus-server-uid # uid設定の変数

    networks:
      - monitoring_default

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager:/etc/alertmanager # Configuration file
    
    command:
      - "--config.file=/etc/alertmanager/alert-config.yml" # See GitHub : https://github.com/prometheus/alertmanager
      - "--log.level=debug"
    expose:
      - '9093'
    restart: always
    networks:
      - monitoring_default

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    expose:
      - '9100'
    networks:
      - monitoring_default
  gpu-exporter:
    image: utkuozdemir/nvidia_gpu_exporter:1.3.0
    # build:
    #   context: .
    #   dockerfile: nvidia_gpu_exporter/Dockerfile
    container_name: nvidia-smi-exporter
    expose:
      - '9835'
        #ports: 
        # - '28004:9835' # host:28004
    restart: unless-stopped
    networks:
      - monitoring_default
    devices:
     - /dev/nvidiactl:/dev/nvidiactl
     - /dev/nvidia0:/dev/nvidia0
    volumes:
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
      - /usr/bin/nvidia-smi:/usr/bin/nvidia-smi
    # いらない
    # deploy:
    #   resources:
    #     limits:
    #       memory: 500M
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities:
    #             - gpu
  
  docker_exporter:
    build:
      context: .
      dockerfile: ./docker_exporter/Dockerfile
    container_name: docker-exporter
    volumes:
      - ./docker_exporter/exporter_py/exporter.py:/exporter/exporter.py
      - /usr/bin/docker:/usr/bin/docker
      - /var/run/docker.sock:/var/run/docker.sock # dockerコマンドのための
    restart: always
    expose:
      - '9999' # start_http_serverでスタートさせたexporterのport
    tty: true
    entrypoint: >
      python3 /exporter/exporter.py
    networks:
      - monitoring_default

  go_exporter:
    build: 
      context: .
      dockerfile: ./go_exporter/Dockerfile
    container_name: go_exporter
    tty: true
    volumes:
      - ./go_exporter/files/:/go/src/app
      # - ./go_exporter/startup.sh:/go/src/app/startup.sh
    # entrypoint: >
    #   go run main.go
    networks: 
      - monitoring_default


volumes:
  metrics_data:
    name: metrics_data
    # external: true

networks:
  monitoring_default:
    # external: true


